{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwiIB7Fa24RAszu5zqXWdA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a65a9dfdda8b455b9400dd6c5fb024be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81e8c778049743ccb95d3315eff2bb2d",
              "IPY_MODEL_5bb8c58288be47cfbd7858d3c99ba539",
              "IPY_MODEL_9c45d10c9b5b470591deef226e1fa6d8"
            ],
            "layout": "IPY_MODEL_bc18782ff9b74361a6678a6c740fb3da"
          }
        },
        "81e8c778049743ccb95d3315eff2bb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6769f316a2f408db34d180f9f8de1f7",
            "placeholder": "​",
            "style": "IPY_MODEL_c5ef45d8d724493bbc84f01abe3ffd3d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5bb8c58288be47cfbd7858d3c99ba539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39ac354ed6ba43a49033eb3d2bc294d6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efb40bfbc41044179a2c6f464aa48fbc",
            "value": 2
          }
        },
        "9c45d10c9b5b470591deef226e1fa6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0faead7d508c4bc69a34f66149fe912c",
            "placeholder": "​",
            "style": "IPY_MODEL_029eb9c958534305a9413844b2aff59b",
            "value": " 2/2 [01:10&lt;00:00, 32.21s/it]"
          }
        },
        "bc18782ff9b74361a6678a6c740fb3da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6769f316a2f408db34d180f9f8de1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ef45d8d724493bbc84f01abe3ffd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39ac354ed6ba43a49033eb3d2bc294d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb40bfbc41044179a2c6f464aa48fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0faead7d508c4bc69a34f66149fe912c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029eb9c958534305a9413844b2aff59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsual/AI_Experiments/blob/main/LLAMA2_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Summarisation Using LLAMA2**"
      ],
      "metadata": {
        "id": "--oS4zhdCa3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZquA1N1CVcb"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3nthkqaCjpI",
        "outputId": "83386be7-ae38-45db-981c-1892191e989a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and modules\n",
        "\n",
        "from langchain import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "# Define the model name/path\n",
        "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# Load the tokenizer associated with the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "\n",
        "# Create a text-generation pipeline using the transformers library\n",
        "# This pipeline will be used for generating text based on the provided model and tokenizer\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\", # The task for which the pipeline is being created\n",
        "    model=model, # The model to be used\n",
        "    tokenizer=tokenizer, # The tokenizer to be used\n",
        "    torch_dtype=torch.bfloat16, # The data type for torch tensors\n",
        "    trust_remote_code=True, # Trust or not trust user code to run on this instance\n",
        "    device_map=\"auto\", # Automatically map to available devices\n",
        "    max_length=1000, # Maximum length for the generated text\n",
        "    do_sample=True, # Whether or not to use sampling in generation\n",
        "    top_k=10, # The number of highest probability vocabulary tokens to keep for top-k-filtering\n",
        "    num_return_sequences=1, # The number of sequences to return\n",
        "    eos_token_id=tokenizer.eos_token_id # The end of sequence token id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a65a9dfdda8b455b9400dd6c5fb024be",
            "81e8c778049743ccb95d3315eff2bb2d",
            "5bb8c58288be47cfbd7858d3c99ba539",
            "9c45d10c9b5b470591deef226e1fa6d8",
            "bc18782ff9b74361a6678a6c740fb3da",
            "d6769f316a2f408db34d180f9f8de1f7",
            "c5ef45d8d724493bbc84f01abe3ffd3d",
            "39ac354ed6ba43a49033eb3d2bc294d6",
            "efb40bfbc41044179a2c6f464aa48fbc",
            "0faead7d508c4bc69a34f66149fe912c",
            "029eb9c958534305a9413844b2aff59b"
          ]
        },
        "id": "tqo1R0vXC8Z0",
        "outputId": "916e791d-39e1-4dba-8f67-a7ece83efa2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a65a9dfdda8b455b9400dd6c5fb024be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the HuggingFacePipeline class\n",
        "# This will serve as a wrapper around the transformers pipeline for easier use with LangChain\n",
        "llm = HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0})"
      ],
      "metadata": {
        "id": "aOq0sdpyDAdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import additional necessary classes\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "# Define the template for the prompt\n",
        "# This template instructs the model on how to structure its response\n",
        "template = \"\"\"\n",
        "              Write a concise summary of the following text delimited by triple backquotes.\n",
        "              Return your response in bullet points which covers the key points of the text.\n",
        "              ```{text}```\n",
        "              BULLET POINT SUMMARY:\n",
        "           \"\"\"\n",
        "\n",
        "# Create an instance of the PromptTemplate class using the defined template\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "\n",
        "# Create an instance of the LLMChain class\n",
        "# This will allow for the execution of the prompt using the defined pipeline\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "# Define the text that needs to be summarized\n",
        "text = \"\"\"\n",
        "Transformers are a type of deep learning model architecture, primarily used in the field of natural language processing (NLP). They were introduced in the paper \"Attention Is All You Need\" by Vaswani et al. in 2017. The key innovation in transformers is the self-attention mechanism that allows the model to weigh the relevance of different words in a sentence, enabling it to capture long-range dependencies in the data.\n",
        "\n",
        "The transformer architecture consists of an encoder and a decoder, though for many tasks like classification, only the encoder part is used. The self-attention mechanism allows each word (or token) in the input data to focus on different parts of the sentence, making it highly flexible and capable of handling a wide range of tasks.\n",
        "\n",
        "In the context of generative AI, transformers have been a game-changer. GPT (Generative Pre-trained Transformer) by OpenAI is a prime example of using transformers for generative tasks. It's trained to predict the next word in a sequence, making it capable of generating coherent and contextually relevant sentences. This capability has led to the development of state-of-the-art models for tasks like text generation, translation, summarization, and more.\n",
        "\n",
        "The success of transformers in NLP has also led to their adoption in other domains, such as computer vision and protein folding, showcasing their versatility.\n",
        "\n",
        "However, training large transformer models requires significant computational resources, and there are challenges related to their interpretability and potential biases in the data they are trained on. Despite these challenges, the transformer architecture's ability to capture intricate patterns in data makes it a cornerstone in the current AI landscape.\n",
        "\"\"\"\n",
        "\n",
        "# Execute the LLMChain with the provided text and print the result\n",
        "print(llm_chain.run(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv4hF5uHF-3f",
        "outputId": "3ad45127-9a02-4226-a617-19616024928c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Transformers are a type of deep learning model architecture primarily used in NLP.\n",
            "            * Introduced in the paper \"Attention Is All You Need\" by Vaswani et al. in 2017.\n",
            "            * Key innovation is the self-attention mechanism that allows the model to weigh the relevance of different words in a sentence.\n",
            "            * Transformer architecture consists of encoder and decoder, though for many tasks only the encoder part is used.\n",
            "            * In generative AI, transformers have been a game-changer, enabling coherent and contextually relevant text generation.\n",
            "            * Success in NLP has led to adoption in other domains, such as computer vision and protein folding.\n",
            "            * Training large transformer models requires significant computational resources, and there are challenges related to interpretability and potential biases in the data.\n",
            "            * Despite challenges, transformer architecture's ability to capture intricate patterns in data makes it a cornerstone in the current AI landscape.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Analysis:**"
      ],
      "metadata": {
        "id": "opK_dpLhGfp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine if a given text is positive, negative, or neutral.\n",
        "sentiment_prompt = \"The sentiment of the text '{}' is:\"\n",
        "text = \"A guy went on Amazon and wrote an amazing review about cow dung cake, complaining that it was not 'crunchy' enough\"\n",
        "result = llm_chain.run(sentiment_prompt.format(text))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vusjFb7GZrO",
        "outputId": "1ee32c35-3906-4b9e-ba1e-7b89fe5fcc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " • The sentiment of the review is not positive.\n",
            "            • The reviewer is unhappy with the texture of the cow dung cake.\n",
            "            • The reviewer expected the cow dung cake to be crunchy.\n",
            "            • The reviewer's overall satisfaction with the product is low.\n",
            "            • The review is written in a humorous tone.\n",
            "            • The review may be intended to be humorous or satirical.\n",
            "            • The review may be a parody or a joke.\n",
            "            • The sentiment of the review is not meant to be taken seriously.\n",
            "            • The review may be intended to be a critique of the product, rather than an honest review.\n",
            "            • The review may be a work of satire or parody.\n",
            "            • The sentiment of the review is not a genuine expression of the reviewer's opinion.\n",
            "            • The review may be a fake or a hoax.\n",
            "            • The review may be intended to deceive or mislead readers.\n",
            "            • The review may be a joke or a prank.\n",
            "            • The sentiment of the review is not a genuine or honest assessment of the product.\n",
            "            • The review may be a fictional or fabricated account.\n",
            "            • The sentiment of the review is not a real or authentic opinion.\n",
            "            • The review may be a parody or a work of satire.\n",
            "            • The sentiment of the review is not meant to be taken seriously.\n",
            "            • The review may be intended to be humorous or ironic.\n",
            "            • The review may be a joke or a prank.\n",
            "            • The sentiment of the review is not a genuine or honest assessment of the product.\n",
            "            • The review may be a fake or a hoax.\n",
            "            • The review may be intended to deceive or mislead readers.\n",
            "            • The review may be a work of satire or parody.\n",
            "            • The sentiment of the review is not a real or authentic opinion.\n",
            "            • The review may be a fictional or fabricated account.\n",
            "            • The sentiment of the review is not a genuine or honest assessment of the product.\n",
            "            • The review may be a parody or a work of satire.\n",
            "            • The sentiment of the review is not meant to be taken seriously.\n",
            "            • The review may be intended to be humorous or ironic.\n",
            "            • The review may be a joke or a prank.\n",
            "            • The sentiment of the review is not a genuine or honest assessment of the product.\n",
            "            • The review may be a fake or a hoax.\n",
            "            • The review may be intended to deceive or mislead readers.\n",
            "            • The review may be a work of satire or parody.\n",
            "            • The sentiment of the review is not a real or authentic opinion.\n",
            "            • The review may be a fictional or fabricated account.\n",
            "            • The sentiment of the review is not a genuine or honest assessment of the product.\n",
            "            • The review may be a parody or a work of satire.\n",
            "            • The sentiment of the review is not meant to be taken seriously.\n",
            "            • The review may be intended to be humorous or ironic.\n",
            "            • The review may be a joke or a prank.\n",
            "            • The sentiment of the review is not a genuine or honest assessment of the product.\n",
            "            • The review may be a fake or a hoax.\n",
            "            • The review may be intended to deceive or mislead readers.\n",
            "            • The review may be a work of satire or parody.\n",
            "            • The sentiment of the review is not a real or authentic opinion.\n",
            "            • The review may be a fictional or fabricated account.\n",
            "            • The sentiment of the review is not a genuine or honest assessment of the product.\n",
            "            • The review may be a parody or a work of satire.\n",
            "            • The sentiment of the review is not meant to be taken seriously.\n",
            "            • The review may be intended to be humorous or ironic.\n",
            "            • The review may be a joke or a prank.\n",
            "            •\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition (NER):**"
      ],
      "metadata": {
        "id": "cl_QHU1AGoXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify and classify named entities in the text, such as person names, organizations, locations, etc.\n",
        "ner_prompt = \"Identify the named entities in the text '{}'.\"\n",
        "text = \"Elon Musk is the CEO of SpaceX.\"\n",
        "result = llm_chain.run(ner_prompt.format(text))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZEzRRnIGZzO",
        "outputId": "cf8ac5d3-b813-4487-e6d4-69425baa53c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " • Elon Musk\n",
            "            • SpaceX\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Translation:**"
      ],
      "metadata": {
        "id": "41zfFCMrGwc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate text from one language to another.\n",
        "translation_prompt = \"Translate the following English text to French: '{}'.\"\n",
        "text = \"Hello, how are you?\"\n",
        "result = llm_chain.run(translation_prompt.format(text))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tStD5ylOG1cW",
        "outputId": "7590aa58-91ca-4ca8-8929-69844843b74f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * 'Hello' is used as a greeting in English\n",
            "            * The phrase 'how are you?' is used to inquire about someone's well-being\n",
            "            * In French, the phrase 'Bonjour, comment vas-tu?' is used to greet someone and ask about their well-being.\n",
            "            * The translation of 'Hello, how are you?' to French is 'Bonjour, comment vas-tu?'.\n",
            "            * The phrase 'Bonjour, comment vas-tu?' is a common greeting used in French to acknowledge someone's presence and ask about their well-being.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question Answering:**"
      ],
      "metadata": {
        "id": "TeBv0838G7sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract answers from a provided context based on a given question.\n",
        "qa_prompt = \"Given the context '{}', what is the answer to the question: '{}'?\"\n",
        "context = \"Albert Einstein was a physicist who developed the theory of relativity.\"\n",
        "question = \"Who developed the theory of relativity?\"\n",
        "result = llm_chain.run(qa_prompt.format(context, question))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXfQxDM-HBcG",
        "outputId": "43f4bd39-4f54-4702-c099-53a8cc6301c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " • Albert Einstein developed the theory of relativity.\n",
            "            • Einstein was a physicist.\n",
            "            • The theory of relativity is a fundamental concept in modern physics.\n",
            "            • Einstein's theory revolutionized our understanding of space and time.\n",
            "            • The theory of relativity has been extensively tested and confirmed through numerous experiments.\n",
            "            • Einstein's work has had a profound impact on the development of modern physics.\n",
            "            • The theory of relativity is a cornerstone of modern physics.\n",
            "            • Einstein's contributions to physics have been recognized and celebrated worldwide.\n",
            "            • The theory of relativity is a fundamental concept in modern physics that has revolutionized our understanding of space and time.\n",
            "            • Einstein's work has had a profound impact on the development of modern physics and continues to influence scientific thought today.\n",
            "            • The theory of relativity is a cornerstone of modern physics that has been extensively tested and confirmed through numerous experiments.\n",
            "            • Einstein's contributions to physics have been recognized and celebrated worldwide as a groundbreaking achievement in the field of science.\n",
            "            • The theory of relativity is a fundamental concept in modern physics that has revolutionized our understanding of space and time, and continues to influence scientific thought today.\n",
            "            • Einstein's work has had a profound impact on the development of modern physics and continues to be celebrated worldwide as a groundbreaking achievement in the field of science.\n",
            "            • The theory of relativity is a cornerstone of modern physics that has been extensively tested and confirmed through numerous experiments, and continues to be a fundamental concept in modern physics today.\n",
            "            • Einstein's contributions to physics have been recognized and celebrated worldwide as a groundbreaking achievement in the field of science, and his work continues to influence scientific thought today.\n",
            "            • The theory of relativity is a fundamental concept in modern physics that has revolutionized our understanding of space and time, and continues to be a cornerstone of modern physics today.\n",
            "            • Einstein's work has had a profound impact on the development of modern physics and continues to be celebrated worldwide as a groundbreaking achievement in the field of science, and his contributions to physics continue to influence scientific thought today.\n",
            "            • The theory of relativity is a fundamental concept in modern physics that has been extensively tested and confirmed through numerous experiments, and continues to be a cornerstone of modern physics today.\n",
            "            • Einstein's contributions to physics have been recognized and celebrated worldwide as a groundbreaking achievement in the field of science, and his work continues to influence scientific thought today.\n",
            "            • The theory of relativity is a fundamental concept in modern physics that has revolutionized our understanding of space and time, and continues to be a cornerstone of modern physics today.\n",
            "            • Einstein's work has had a profound impact on the development of modern physics and continues to be celebrated worldwide as a groundbreaking achievement in the field of science, and his contributions to physics continue to influence scientific thought today.\n",
            "            • The theory of relativity is a fundamental concept in modern physics that has been extensively tested and confirmed through numerous experiments, and continues to be a cornerstone of modern physics today.\n",
            "            • Einstein's contributions to physics have been recognized and celebrated worldwide as a groundbreaking achievement in the field of science, and his work continues to influence scientific thought today.\n",
            "            • The theory of relativity is a fundamental concept in modern physics that has revolutionized our understanding of space and time, and continues to be a cornerstone of modern physics today.\n",
            "            • Einstein's work has had a profound impact on the development of modern physics and continues to be celebrated worldwide as a groundbreaking achievement in the field of science, and his contributions to physics continue to influence scientific thought today.\n",
            "            • The theory of relativity is a fundamental concept in modern physics that has been extensively tested and confirmed through numerous experiments, and continues to be a cornerstone of modern physics today.\n",
            "            • Einstein's contributions to physics have been recognized and celebrated worldwide as a groundbreaking achievement in the field of science, and his work continues to influence scientific thought today.\n",
            "           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Classification:**"
      ],
      "metadata": {
        "id": "w6EHxV_GHF6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify text into predefined categories.\n",
        "classification_prompt = \"Classify the following text into a category: '{}'.\"\n",
        "text = \"The food was amazing!\"\n",
        "result = llm_chain.run(classification_prompt.format(text))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWhsBQ3mHHpm",
        "outputId": "a8042200-485b-4177-ca15-f821b960a6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - The text is a positive review of food.\n",
            "            - The word 'amazing' is used to describe the quality of the food.\n",
            "            - The text expresses enthusiasm and satisfaction with the food.\n",
            "            - The text is categorized as a positive review.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero-shot Classification:**"
      ],
      "metadata": {
        "id": "UoXxWRXPHPiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify text into categories without having seen those categories during training.\n",
        "zero_shot_prompt = \"Given the text '{}', which category does it belong to among the options: {}?\"\n",
        "text = \"The movie was filled with suspense and unexpected twists.\"\n",
        "categories = [\"entertainment\", \"technology\", \"politics\"]\n",
        "result = llm_chain.run(zero_shot_prompt.format(text, \", \".join(categories)))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plSKeW1vHTh6",
        "outputId": "f73f3f0f-4ca9-4e89-add0-0a1425febfb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " • Suspense\n",
            "            • Unexpected twists\n",
            "            • Movie\n",
            "            • Entertainment\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Completion:**"
      ],
      "metadata": {
        "id": "4vfWIM5MHXT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete a given text prompt.\n",
        "completion_prompt = \"Complete the following story: '{}'.\"\n",
        "text = \"Once upon a time,\"\n",
        "result = llm_chain.run(completion_prompt.format(text))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqeE48x_HbOZ",
        "outputId": "37d7c7ee-1fd2-4f25-ecb8-06b3e2d54473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - The story begins with the phrase \"Once upon a time,\" indicating that it is a fairy tale or fantasy story.\n",
            "            - The story is set in a magical forest, where animals can talk and there are mysterious creatures.\n",
            "            - The main character, a young girl, goes on a journey to find a rare flower that only grows on the highest mountain in the land.\n",
            "            - Along the way, she meets a wise old owl who offers her advice and guidance.\n",
            "            - The girl faces various challenges and obstacles, including fierce storms and treacherous terrain.\n",
            "            - Despite these challenges, she perseveres and eventually reaches the top of the mountain, where she finds the rare flower.\n",
            "            - The flower has magical powers and can grant wishes, and the girl is overjoyed at her discovery.\n",
            "            - The story concludes with the girl returning home, where she shares her adventure with her friends and family.\n",
            "            - The story is a classic tale of perseverance and determination, highlighting the importance of never giving up on one's dreams.\n",
            "            - The magical forest and the rare flower add a sense of wonder and enchantment to the story, making it a delightful and imaginative read.\n",
            "            - The story also teaches valuable lessons about the power of perseverance and the importance of following one's dreams, making it a timeless and inspiring tale.\n",
            "            - The use of descriptive language and vivid imagery throughout the story creates a rich and immersive reading experience, drawing the reader into the magical world of the forest.\n",
            "            - The story is a reminder that anything is possible if we are willing to work hard and never give up on our dreams, no matter how impossible they may seem.\n",
            "            - The story is a classic tale of adventure, fantasy, and self-discovery, making it a delightful and inspiring read for readers of all ages.\n",
            "            - The story is a reminder that the journey is just as important as the destination, and that the lessons we learn along the way are invaluable.\n",
            "            - The story is a timeless tale that will continue to inspire and delight readers for generations to come.\n",
            "            - The story is a reminder that the power of imagination and creativity can take us on incredible journeys and lead us to incredible discoveries.\n",
            "            - The story is a reminder that the world is full of magic and wonder, and that we should never stop exploring and discovering new things.\n",
            "            - The story is a reminder that the journey of self-discovery is a lifelong journey, and that we should always be open to new experiences and adventures.\n",
            "            - The story is a reminder that the power of perseverance and determination can lead us to incredible success and happiness.\n",
            "            - The story is a reminder that the world is full of beauty and wonder, and that we should always be open to new experiences and adventures.\n",
            "            - The story is a reminder that the journey of life is full of challenges and obstacles, but with perseverance and determination, we can overcome them and achieve our dreams.\n",
            "            - The story is a reminder that the power of imagination and creativity can take us on incredible journeys and lead us to incredible discoveries.\n",
            "            - The story is a reminder that the world is full of magic and wonder, and that we should never stop exploring and discovering new things.\n",
            "            - The story is a reminder that the journey of self-discovery is a lifelong journey, and that we should always be open to new experiences and adventures.\n",
            "            - The story is a reminder that the power of perseverance and determination can lead us to incredible success and happiness.\n",
            "            - The story is a reminder that the journey of life is full of challenges and obstacles, but with perseverance and determination, we can overcome them and achieve our dreams.\n",
            "            - The story is a reminder that the power of imagination and creativity can take us on incredible journeys and lead us to incredible discoveries.\n",
            "            - The story is a reminder that the world is full\n"
          ]
        }
      ]
    }
  ]
}